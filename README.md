# Kafka Streams POC


![image](https://user-images.githubusercontent.com/13722755/181151359-e4d93083-676a-4c80-be55-5270a6f1ccfb.png)


This three-tiered application routes messages to a consumer based on rules. The rules are contained within the yaml configuration file.  The producer of the messages is the load generator service. The load generator service creates a configurable amount of messages, in a configurable format. 

This was modified from an application used for a customer in 2017.  This application could be extended to be a much richer routing system. 

## Load Generator 

The fields are generated by a field generation service that send messages to a kafka broker through a REST proxy.  The config file is read in and a workload is created with the user being able to choose the data types and ranges of the messages.  The messages throughput can be configured as well for load testing.

## Business Tier service

The yaml is read into the business tier service and the rules are applied to the proper messages.  KafkaStreams API is used to create a toplogy with all fo the rules processing and filterint coming from the yaml.  The idea is to show how robust the rules processing can be with this type of architecture. The messages are passed to a kafka broker through a REST proxy.

## Consumer 

A yaml file is read to and have the configurations for the rules processing. KafkaStreams API is used to implement a topolgy similar to the business tier. Dead letter queue, sinks are also part of the message processing. Also uses the confluent REST proxy, same as the business tier.


